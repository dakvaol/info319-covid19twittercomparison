{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_for_hydrate(df, name):\n",
    "    df = df[0]\n",
    "    df.to_csv(r\"Tweets\\ready_\"+ str(name), index=False, header=None)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#DONT RUN THIS IF YOU DON'T PLAN TO EXTRACTING TWEETS YOUR SELF,\n",
    "#This makes it possible for one to use the hydrator on the \"ready_date.csv\" files\n",
    "#It removes the sentiment score and saves the file with the method above\n",
    "\n",
    "\n",
    "#Period 1\n",
    "#March 21-22\n",
    "\n",
    "march21_22 = pd.read_csv(r\"Tweets\\march21_march22.csv\", header=None)\n",
    "march21_22 = ready_for_hydrate(march21_22, \"october15_october16.csv\")\n",
    "\n",
    "\n",
    "#March 22-23\n",
    "march22_23 = pd.read_csv(r\"Tweets\\march22_march23.csv\", header=None)\n",
    "march22_23 = ready_for_hydrate(march22_23, \"march22_march23.csv\")\n",
    "\n",
    "#March23-24\n",
    "march23_24 = pd.read_csv(r\"Tweets\\march23_march24.csv\", header=None)\n",
    "march23_24 = ready_for_hydrate(march23_24, \"march23_march24.csv\")\n",
    "\n",
    "#Period 2\n",
    "\n",
    "#July5_July6\n",
    "july5_6 = pd.read_csv(r\"Tweets\\july5_july6.csv\", header=None)\n",
    "july5_6 = ready_for_hydrate(july5_6, \"july5_july6.csv\")\n",
    "\n",
    "#July6_July7\n",
    "july6_7 = pd.read_csv(r\"Tweets\\july6_july7.csv\", header=None)\n",
    "july6_7 = ready_for_hydrate(july6_7, \"july6_july7.csv\")\n",
    "\n",
    "#July7_July8\n",
    "july7_8 = pd.read_csv(r\"Tweets\\july7_july8.csv\", header=None)\n",
    "july7_8 = ready_for_hydrate(july7_8, \"july7_july8.csv\")\n",
    "\n",
    "\n",
    "#Period 3\n",
    "#October13_October14\n",
    "oct13_14 = pd.read_csv(r\"Tweets\\october13_october14.csv\", header=None)\n",
    "oct13_14 = ready_for_hydrate(oct13_14, \"october13_october14.csv\")\n",
    "\n",
    "#october14_october15\n",
    "oct14_15 = pd.read_csv(r\"Tweets\\october14_october15.csv\", header=None)\n",
    "oct14_15 = ready_for_hydrate(oct14_15 , \"october14_october15.csv\")\n",
    "\n",
    "\n",
    "#october 15_october16\n",
    "oct15_16 = pd.read_csv(r\"Tweets\\october15_october16.csv\", header=None)\n",
    "oct15_16 = ready_for_hydrate(oct15_16 ,\"october15_october16.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a method to extract the longitudes and latitudes from the files\n",
    "#As the gps cooridnates is in a json file we need to make a for loop where each line\n",
    "#is a  json str object and then if the object is coordinates we extract the coordintes\n",
    "#To their corresponding Latitude and longitude lists\n",
    "\n",
    "\n",
    "def get_coordinates(json_list):\n",
    "    longitude = []\n",
    "    latitude = []\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        if result['coordinates']:\n",
    "            coords = result['coordinates']\n",
    "            lat = coords[\"coordinates\"][1]\n",
    "            lon = coords[\"coordinates\"][0]\n",
    "            latitude.append(lat)\n",
    "            longitude.append(lon)\n",
    "    return latitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods that opens the jsonl files with the corrext encoding then utilizes the \n",
    "#method above to to combine latitude adn longitude into one Dataframe\n",
    "\n",
    "\n",
    "column_names = [\"Latitude\", \"Longitude\"]\n",
    "\n",
    "\n",
    "def getTweets(file):\n",
    "    with open(file, 'r',\n",
    "          encoding='utf-8') as json_file:\n",
    "        json_file = list(json_file)\n",
    "\n",
    "    lon_json, lat_json =get_coordinates(json_file)\n",
    "\n",
    "    gps_json = pd.DataFrame(columns = column_names)\n",
    "    gps_json['Latitude'] = lon_json\n",
    "    gps_json['Longitude'] = lat_json\n",
    "    return gps_json\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 22_23, gps_march22_23:      Latitude   Longitude\n",
      "0  34.576585  135.994134\n",
      "1  19.136725   72.820891\n",
      "2  18.561727   73.810894\n",
      "March 23_24, gps_march23_24:      Latitude   Longitude\n",
      "0  38.423175 -121.424536\n",
      "1  33.948100 -117.396000\n",
      "2  28.560300  -81.584100\n",
      "July 5-6     Latitude   Longitude\n",
      "0  37.709524 -122.452213\n",
      "1  40.576518  -73.985581\n",
      "2  38.194068  -85.775006\n",
      "July 6_7, gps_july6_7:      Latitude   Longitude\n",
      "0 -37.794500  144.930000\n",
      "1  47.610387 -122.334909\n",
      "2  39.486400 -106.044000\n",
      "July 7-8, gps_july7_8:      Latitude   Longitude\n",
      "0   2.725300  101.938700\n",
      "1  -3.448223   35.978611\n",
      "2 -37.798000  144.976860\n",
      "October 13_14, gps_oct13_14:      Latitude  Longitude\n",
      "0  51.953620  -0.284690\n",
      "1  51.747772  -1.313531\n",
      "2  51.642359  -2.673735\n",
      "October 14-16, gps_oct14_15:      Latitude   Longitude\n",
      "0  51.747711   -1.313546\n",
      "1   3.400724  101.839535\n",
      "2  51.505390   -0.124860\n",
      "October15-16:      Latitude   Longitude\n",
      "0   8.570497   76.868591\n",
      "1  34.056400 -118.244500\n",
      "2  52.244933    0.710803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Calling the above functions to only store the actual gps coordinates of the tweets in \n",
    "#Dataframes for days we have extracted\n",
    "#The .jsonl files is what is left after hydrating the csv files above. \n",
    "\n",
    "#Period 1\n",
    "#March21-22\n",
    "gps_march21_22 = getTweets(\"Tweets/tweets_march21_march22.jsonl\")\n",
    "\n",
    "#March22_23\n",
    "gps_march22_23 = getTweets(\"Tweets/tweets_march22_march23.jsonl\")\n",
    "print(\"March 22_23, gps_march22_23: \",gps_march22_23.head(3))\n",
    "\n",
    "#March23_24\n",
    "gps_march23_24 = getTweets(\"Tweets/tweets_march23_march24.jsonl\")\n",
    "print(\"March 23_24, gps_march23_24: \", gps_march23_24.head(3))\n",
    "\n",
    "#Period 2\n",
    "#July5-6\n",
    "gps_july5_6 = getTweets(\"Tweets/tweets_july5_july6.jsonl\")\n",
    "print(\"July 5-6\", gps_july5_6.head(3))\n",
    "\n",
    "\n",
    "#July6-7\n",
    "gps_july6_7 = getTweets(\"Tweets/tweets_july6_july7.jsonl\")\n",
    "print(\"July 6_7, gps_july6_7: \", gps_july6_7.head(3))\n",
    "\n",
    "\n",
    "#July7-8\n",
    "gps_july7_8 = getTweets(\"Tweets/tweets_july7_july8.jsonl\")\n",
    "print(\"July 7-8, gps_july7_8: \", gps_july7_8.head(3))\n",
    "\n",
    "\n",
    "\n",
    "#Period 3 \n",
    "#October13_14\n",
    "gps_oct13_14 = getTweets(\"Tweets/tweets_october13_october14.jsonl\")\n",
    "print(\"October 13_14, gps_oct13_14: \", gps_oct13_14.head(3))\n",
    "\n",
    "\n",
    "#October14_15\n",
    "gps_oct14_15 = getTweets(\"Tweets/tweets_october14_october15.jsonl\")\n",
    "print(\"October 14-16, gps_oct14_15: \", gps_oct14_15.head(3))\n",
    "\n",
    "\n",
    "#October15_16\n",
    "gps_oct15_16 = getTweets(\"Tweets/tweets_october15_october16.jsonl\")\n",
    "print(\"October15-16: \", gps_oct15_16.head(3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Combines the different datasets representing datasets into 1\n",
    "#As we only uses 3days ths is set to handle 3 days\n",
    "def combine_days_lat_long(day1, day2, day3):\n",
    "    tweets_lat =[]\n",
    "    d1_2_lat = list(day1['Latitude'])\n",
    "    d2_3_lat = list(day2['Latitude'])\n",
    "    d3_4_lat = list(day3['Latitude'])\n",
    "    days_tweets_lat = d1_2_lat + d2_3_lat + d3_4_lat\n",
    "\n",
    "    tweets_lon =[]\n",
    "    d1_2_lon = list(day1['Longitude'])\n",
    "    d2_3_lon = list(day2['Longitude'])\n",
    "    d3_4_lon = list(day3['Longitude'])\n",
    "    days_tweets_lon = d1_2_lon + d2_3_lon + d3_4_lon\n",
    "\n",
    "    period_tweets_gps = pd.DataFrame(columns = column_names)\n",
    "    period_tweets_gps['Latitude'] = days_tweets_lat\n",
    "    period_tweets_gps['Longitude'] = days_tweets_lon\n",
    "    print(\"Number of tweets from period given: \",len(period_tweets_gps))\n",
    "    print(period_tweets_gps.head(3))\n",
    "    return period_tweets_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets from period given:  3034\n",
      "    Latitude  Longitude\n",
      "0  41.792764 -87.732524\n",
      "1   6.583750   3.975540\n",
      "2  40.700000 -73.830900\n",
      "Number of tweets from period given:  3925\n",
      "    Latitude   Longitude\n",
      "0  37.709524 -122.452213\n",
      "1  40.576518  -73.985581\n",
      "2  38.194068  -85.775006\n",
      "Number of tweets from period given:  1561\n",
      "    Latitude  Longitude\n",
      "0  51.953620  -0.284690\n",
      "1  51.747772  -1.313531\n",
      "2  51.642359  -2.673735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Combines the different days into one dataframe for each period\n",
    "march_tweets_gps = combine_days_lat_long(gps_march21_22, gps_march22_23, gps_march23_24)\n",
    "\n",
    "july_tweets_gps = combine_days_lat_long(gps_july5_6, gps_july6_7, gps_july7_8)\n",
    "\n",
    "october_tweets_gps = combine_days_lat_long(gps_oct13_14, gps_oct14_15, gps_oct15_16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the data as a csv file\n",
    "#Which then can be used by the other scripts\n",
    "march_tweets_gps.to_csv(\"useddata\\march_tweets_gps.csv\", index=False)\n",
    "july_tweets_gps.to_csv(\"useddata\\july_tweets_gps.csv\", index=False)\n",
    "october_tweets_gps.to_csv(\"useddata\\october_tweets_gps.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
